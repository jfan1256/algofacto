{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6c7bbc",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fcd7a0",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import polars as pl\n",
    "\n",
    "from functions.utils.func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c3c98",
   "metadata": {},
   "source": [
    "# OHCLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ded06e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T19:25:03.652284900Z",
     "start_time": "2023-08-01T19:25:03.636039800Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_ohclv():\n",
    "    price_data = pd.read_parquet(get_load_data_large_dir() / 'ohclv_sp500_all.parquet')\n",
    "    price_data = price_data.rename(\n",
    "        columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'vol': 'Volume', }).drop(\n",
    "        ['industry', 'subindustry'], axis=1)\n",
    "    price_data.index.name = 'date'\n",
    "    price_data = price_data.reset_index('date').sort_values(['ticker', 'date']).set_index(['ticker', 'date'])\n",
    "    price_data = price_data.astype(float)\n",
    "    price_data.to_parquet(get_load_data_parquet_dir() / 'data_price.parquet.brotli', compression='brotli')\n",
    "    data_date = price_data.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis=1)\n",
    "    data_date.to_parquet(get_load_data_parquet_dir() / 'data_date.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d7ffe6c9457314",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ohclv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c97c128d930bcbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T18:09:12.441373800Z",
     "start_time": "2023-08-17T18:09:11.693507800Z"
    }
   },
   "outputs": [],
   "source": [
    "price_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_price.parquet.brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a69f854d7ac72a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_date.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e590d2b",
   "metadata": {},
   "source": [
    "# Fama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a6b51e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T19:21:56.862578200Z",
     "start_time": "2023-08-03T19:21:56.843341Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_fama():\n",
    "    fama_data = (web.DataReader('F-F_Research_Data_5_Factors_2x3_daily', 'famafrench', start=1990)[0].rename(columns={'Mkt-RF': 'MARKET'}))\n",
    "    fama_data.index.names = ['date']\n",
    "    fama_data = fama_data.astype(float)\n",
    "    fama_data.to_parquet(get_load_data_parquet_dir() / 'data_fama.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3da433256bf0c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T19:21:59.133594400Z",
     "start_time": "2023-08-03T19:21:57.469391700Z"
    }
   },
   "outputs": [],
   "source": [
    "create_fama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d54bf078bed94a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fama = pd.read_parquet(get_load_data_parquet_dir() / 'data_fama.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a76f781",
   "metadata": {},
   "source": [
    "# Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13271812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ind():\n",
    "    ind_data = pd.read_parquet(get_load_data_large_dir() / 'ohclv_sp500_all.parquet')\n",
    "    ind_data = ind_data.rename(\n",
    "        columns={'industry': 'Industry', 'subindustry': 'Subindustry'}).drop(\n",
    "        ['open', 'high', 'low', 'close', 'vol'], axis=1)\n",
    "    ind_data.index.name = 'date'\n",
    "    ind_data = ind_data.reset_index('date').sort_values(['ticker', 'date']).set_index(['ticker', 'date'])\n",
    "    ind_data = ind_data.astype(float)\n",
    "    ind_data.to_parquet(get_load_data_parquet_dir() / 'data_ind.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81ccd870b15a902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86de8e52cbc28ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T18:17:19.994700600Z",
     "start_time": "2023-08-17T18:17:19.417971600Z"
    }
   },
   "outputs": [],
   "source": [
    "ind = pd.read_parquet(get_load_data_parquet_dir() / 'data_ind.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35d4a6",
   "metadata": {},
   "source": [
    "# Fundamental Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "963d8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fund_ratio(self):\n",
    "    fund_data = pd.read_csv(get_load_data_large_dir() / 'wrds_fundamentals_raw_factor.csv')\n",
    "    fund_data['date_index'] = pd.to_datetime(fund_data['date_index'])\n",
    "    fund_data = fund_data.rename(columns={'date_index': 'date'}).set_index(['ticker', 'date'])\n",
    "    fund_data = fund_data.drop(['fyearq', 'cash_flow', 'gross_assets', 'net_operating_assets',\n",
    "       'total_debt', 'total_earning_assets', 'working_capital'], axis=1)\n",
    "    fund_data = fund_data.astype(float)\n",
    "    fund_data.to_parquet(get_load_data_parquet_dir() / 'data_fund_ratio.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ffaae94d0b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fund_ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf313769b5b792ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T02:35:12.112307100Z",
     "start_time": "2023-08-01T02:35:10.847842500Z"
    }
   },
   "outputs": [],
   "source": [
    "fund_ratio = pd.read_parquet(get_load_data_parquet_dir() / 'data_fund_ratio.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb11edc",
   "metadata": {},
   "source": [
    "# Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41579ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T19:34:34.389161700Z",
     "start_time": "2023-08-15T19:34:34.285161400Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_macro():\n",
    "    IF = pd.read_csv(get_load_data_large_dir() / 'macro' / 'fiveYearIR.csv')\n",
    "    IF.columns = ['date', '5YIF']\n",
    "    IF = IF.set_index(pd.to_datetime(IF['date'])).drop('date', axis=1)\n",
    "\n",
    "    medianCPI = pd.read_csv(get_load_data_large_dir() / 'macro' / 'medianCPI.csv')\n",
    "    medianCPI.columns = ['date', 'medCPI']\n",
    "    medianCPI = medianCPI.set_index(pd.to_datetime(medianCPI['date'])).drop('date', axis=1)\n",
    "    medianCPI = medianCPI.shift(1)\n",
    "\n",
    "    rGDP = pd.read_csv(get_load_data_large_dir() / 'macro' / 'realGDP.csv')\n",
    "    rGDP.columns = ['date', 'rGDP']\n",
    "    rGDP = rGDP.set_index(pd.to_datetime(rGDP['date'])).drop('date', axis=1)\n",
    "\n",
    "    rIR = pd.read_csv(get_load_data_large_dir() / 'macro' / 'realInterestRate.csv')\n",
    "    rIR.columns = ['date', 'rIR']\n",
    "    rIR = rIR.set_index(pd.to_datetime(rIR['date'])).drop('date', axis=1)\n",
    "    rIR = rIR.shift(1)\n",
    "\n",
    "    UR = pd.read_csv(get_load_data_large_dir() / 'macro' / 'unemploymentRate.csv')\n",
    "    UR.columns = ['date', 'UR']\n",
    "    UR = UR.set_index(pd.to_datetime(UR['date'])).drop('date', axis=1)\n",
    "    UR = UR.shift(1)\n",
    "\n",
    "    TB = pd.read_csv(get_load_data_large_dir() / 'macro' / 'TB.csv')\n",
    "    TB.columns = ['date', 'TB']\n",
    "    TB = TB.set_index(pd.to_datetime(TB['date'])).drop('date', axis=1)\n",
    "    TB = TB.shift(1)\n",
    "    \n",
    "    PPI = pd.read_csv(get_load_data_large_dir() / 'macro' / 'PPI.csv')\n",
    "    PPI.columns = ['date', 'PPI']\n",
    "    PPI = PPI.set_index(pd.to_datetime(PPI['date'])).drop('date', axis=1)\n",
    "    PPI = PPI.shift(1)\n",
    "    \n",
    "    retailSales = pd.read_csv(get_load_data_large_dir() / 'macro' / 'retailSales.csv')\n",
    "    retailSales.columns = ['date', 'retailSales']\n",
    "    retailSales = retailSales.set_index(pd.to_datetime(retailSales['date'])).drop('date', axis=1)\n",
    "    retailSales = retailSales.shift(1)\n",
    "    \n",
    "    indProdIndex = pd.read_csv(get_load_data_large_dir() / 'macro' / 'indProdIndex.csv')\n",
    "    indProdIndex.columns = ['date', 'indProdIndex']\n",
    "    indProdIndex = indProdIndex.set_index(pd.to_datetime(indProdIndex['date'])).drop('date', axis=1)\n",
    "    indProdIndex = indProdIndex.shift(1)\n",
    "\n",
    "    realDispoIncome = pd.read_csv(get_load_data_large_dir() / 'macro' / 'realDispoIncome.csv')\n",
    "    realDispoIncome.columns = ['date', 'realDispoIncome']\n",
    "    realDispoIncome = realDispoIncome.set_index(pd.to_datetime(realDispoIncome['date'])).drop('date', axis=1)\n",
    "    realDispoIncome = realDispoIncome.shift(1)\n",
    "    \n",
    "    def pctChange(data, name):\n",
    "        data.replace('.', np.nan, inplace=True)\n",
    "        data = data.astype(float)\n",
    "        data[f'{name}_pct']=data[f'{name}'].pct_change()\n",
    "        return data\n",
    "    \n",
    "    IF = pctChange(IF, '5YIF')\n",
    "    medianCPI = pctChange(medianCPI, 'medCPI')\n",
    "    rGDP = pctChange(rGDP, 'rGDP')\n",
    "    rIR = pctChange(rIR, 'rIR')\n",
    "    UR = pctChange(UR, 'UR')\n",
    "    TB = pctChange(TB, 'TB')\n",
    "    PPI = pctChange(PPI, 'PPI')\n",
    "    retailSales = pctChange(retailSales, 'retailSales')\n",
    "    indProdIndex = pctChange(indProdIndex, 'indProdIndex')\n",
    "    realDispoIncome = pctChange(realDispoIncome, 'realDispoIncome')\n",
    "    \n",
    "    macro = (pd.merge(IF, medianCPI, left_index=True, right_index=True, how='left').ffill()\n",
    "                 .merge(rGDP, left_index=True, right_index=True, how='left').ffill()\n",
    "                 .merge(rIR, left_index=True, right_index=True, how='left').ffill()\n",
    "                 .merge(UR, left_index=True, right_index=True, how='left').ffill()\n",
    "                 .merge(TB, left_index=True, right_index=True, how='left').ffill()\n",
    "                 .merge(PPI, left_index=True, right_index=True, how='left').ffill()\n",
    "                 .merge(retailSales, left_index=True, right_index=True, how='left').ffill()\n",
    "                 .merge(indProdIndex, left_index=True, right_index=True, how='left').ffill()\n",
    "                 .merge(realDispoIncome, left_index=True, right_index=True, how='left').ffill())\n",
    "    \n",
    "    factor_macro = macro[['5YIF_pct', 'medCPI_pct', 'rGDP_pct', 'rIR_pct', 'UR_pct', 'TB_pct', 'PPI_pct', 'retailSales_pct', 'indProdIndex_pct', 'realDispoIncome_pct']]\n",
    "    \n",
    "    def normalize(df):\n",
    "        df = (df[-1]-df.mean())/df.std()\n",
    "        return df\n",
    "    \n",
    "    factor_macro['5YIF_pct'] = factor_macro['5YIF_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['medCPI_pct'] = factor_macro['medCPI_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['rGDP_pct'] = factor_macro['rGDP_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['rIR_pct'] = factor_macro['rIR_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['UR_pct'] = factor_macro['UR_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['TB_pct'] = factor_macro['TB_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['PPI_pct'] = factor_macro['PPI_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['retailSales_pct'] = factor_macro['retailSales_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['indProdIndex_pct'] = factor_macro['indProdIndex_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "    factor_macro['realDispoIncome_pct'] = factor_macro['realDispoIncome_pct'].rolling(30).apply(lambda x: normalize(x))\n",
    "\n",
    "    \n",
    "    factor_macro['medCPI_div_rGDP'] = (macro['medCPI'] / macro['rGDP']).pct_change()\n",
    "    factor_macro['5YIF_div_medCPI'] = (macro['5YIF']/macro['medCPI']).pct_change()\n",
    "    \n",
    "    factor_macro = factor_macro.replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "    factor_macro.to_parquet(get_load_data_parquet_dir() / 'data_macro.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79bb3697d576d3e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T19:34:45.762488900Z",
     "start_time": "2023-08-15T19:34:35.114159700Z"
    }
   },
   "outputs": [],
   "source": [
    "create_macro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7588e22543ff09c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T19:34:45.816487600Z",
     "start_time": "2023-08-15T19:34:45.766488200Z"
    }
   },
   "outputs": [],
   "source": [
    "macro = pd.read_parquet(get_load_data_parquet_dir() / 'data_macro.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734bc03d",
   "metadata": {},
   "source": [
    "# ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "783e39cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T19:21:42.010959700Z",
     "start_time": "2023-08-03T19:21:41.948971Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_etf():\n",
    "    etf_tickers = pl.scan_csv(get_load_data_large_dir() / 'tickers_etf.csv').collect(\n",
    "        streaming=True).to_series().to_list()\n",
    "    start_date = \"1999-01-01\"\n",
    "    end_date = \"2023-03-20\"\n",
    "    etf_data = yf.download(etf_tickers, start=start_date, end=end_date)\n",
    "    etf_data = etf_data.stack().swaplevel().sort_index()\n",
    "    etf_data.index.names = ['ticker', 'date']\n",
    "    etf_data = etf_data.astype(float)\n",
    "\n",
    "    # Calculate returns of each ticker and rename each return column to ticker\n",
    "    ret = etf_data.groupby('ticker')['Close'].apply(lambda x: x.pct_change())\n",
    "    ret_df = ret.unstack(level='ticker')\n",
    "    dates = etf_data.reset_index('ticker').drop(\n",
    "        ['ticker', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], axis=1)\n",
    "    dates = dates.loc[~dates.index.duplicated(keep='first')].sort_index()\n",
    "    etf_data = pd.concat([dates, ret_df], axis=1)\n",
    "    etf_data.to_parquet(get_load_data_parquet_dir() / 'data_etf.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8e358571eff1182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T19:21:45.497396500Z",
     "start_time": "2023-08-03T19:21:43.209472400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    }
   ],
   "source": [
    "create_etf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "21b0977f334fe3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf = pd.read_parquet(get_load_data_parquet_dir() / 'data_etf.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60196f96",
   "metadata": {},
   "source": [
    "# PCA Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "181e8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca_return():\n",
    "    # Read in price data and set time frame and remove data with less than 2 years length of data (same data as create_factor.py)\n",
    "    price_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_price.parquet.brotli')\n",
    "    price_data = set_timeframe(price_data, '2002-01-01', '2023-01-01')\n",
    "    price_data = set_length(price_data, year=2)\n",
    "\n",
    "    # Create returns and convert ticker index to columns\n",
    "    price_data = create_return(price_data, windows=[1])\n",
    "    ret = price_data[[f'RET_01']]\n",
    "    ret = ret['RET_01'].unstack('ticker')\n",
    "    ret.iloc[0] = ret.iloc[0].fillna(0)\n",
    "\n",
    "    # Execute Rolling PCA\n",
    "    window_size=60\n",
    "    num_components=5\n",
    "    pca_return = rolling_pca(data=ret, window_size=window_size, num_components=num_components, name='Return')\n",
    "    pca_return.to_parquet(get_load_data_parquet_dir() / 'data_pca_ret.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "173eb908e12e1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pca_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "118d16d4d1216ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ret = pd.read_parquet(get_load_data_parquet_dir() / 'data_pca_ret.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687cf656663499a8",
   "metadata": {},
   "source": [
    "# All RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f22ecbda1ea627f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T04:59:51.021950200Z",
     "start_time": "2023-08-18T04:59:51.006222Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_all_rf():\n",
    "    etf_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_etf.parquet.brotli')\n",
    "    fama_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_fama.parquet.brotli')\n",
    "    pca_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_pca_ret.parquet.brotli')\n",
    "    macro_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_macro.parquet.brotli')\n",
    "    all_rf = pd.concat([etf_data, fama_data, pca_data, macro_data], axis=1)\n",
    "    all_rf = set_timeframe(all_rf, '2002-01-01', '2023-01-01')\n",
    "    fama_data = set_timeframe(fama_data, '2002-01-01', '2023-01-01')\n",
    "    # Execute Rolling PCA\n",
    "    window_size=60\n",
    "    num_components=5\n",
    "    pca_rf = rolling_pca(data=all_rf, window_size=window_size, num_components=num_components, name='RF')\n",
    "    # Add risk-free rate\n",
    "    pca_rf = pd.concat([pca_rf, fama_data['RF']], axis=1)    \n",
    "    pca_rf.to_parquet(get_load_data_parquet_dir() / 'data_all_rf.parquet.brotli', compression = 'brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94c22790e32c72d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T04:59:51.280300800Z",
     "start_time": "2023-08-18T04:59:51.021950200Z"
    }
   },
   "outputs": [],
   "source": [
    "create_all_rf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ea83c9000b47430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T04:59:51.493998300Z",
     "start_time": "2023-08-18T04:59:51.452168100Z"
    }
   },
   "outputs": [],
   "source": [
    "all_rf = pd.read_parquet(get_load_data_parquet_dir() / 'data_all_rf.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c584461ae8388b7",
   "metadata": {},
   "source": [
    "# SPY Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5b3dc9d50b04643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T19:13:41.355094600Z",
     "start_time": "2023-08-15T19:13:41.326094800Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_spy_return():\n",
    "    spy_return = get_spy('2006-01-01', '2023-01-01')\n",
    "    spy_return.index.name = 'date'\n",
    "    spy_return.to_parquet(get_load_data_parquet_dir() / 'data_spy.parquet.brotli', compression = 'brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aead082bf9c15ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T19:13:43.122333800Z",
     "start_time": "2023-08-15T19:13:42.460472900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "create_spy_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e1cfa6485265f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T19:13:49.136059500Z",
     "start_time": "2023-08-15T19:13:49.104073600Z"
    }
   },
   "outputs": [],
   "source": [
    "spy_return = pd.read_parquet(get_load_data_parquet_dir() / 'data_spy.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74bbc33",
   "metadata": {},
   "source": [
    "# Open Asset Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680e2785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_open_asset_pricing():\n",
    "    oap_data = pd.read_parquet(get_load_data_large_dir() / 'signed_predictors_dl_wide.parquet.brotli')\n",
    "    permno_codes = pd.read_csv(get_load_data_large_dir() / 'permno.csv')\n",
    "    factors_to_use = ['DivSeason', 'ChTax', 'EarningsStreak', 'ResidualMomentum', 'AssetGrowth',\n",
    "                  'NOA', 'SmileSlope', 'MomSeasonShort', 'InvestPPEInv', 'NetDebtFinance', 'InvGrowth', 'MomSeason11YrPlus']\n",
    "\n",
    "    oap_data = oap_data[['permno', 'yyyymm'] + factors_to_use]\n",
    "    permno_codes = permno_codes[['LPERMNO', 'tic']].rename(columns={'LPERMNO':'permno'})\n",
    "\n",
    "    permno_unique = permno_codes.drop_duplicates().sort_values(by='permno')\n",
    "\n",
    "    permno_unique = dict(zip(permno_unique['permno'], permno_unique['tic']))\n",
    "\n",
    "    oap_filtered = oap_data[oap_data['permno'].isin(permno_unique.keys())]\n",
    "    oap_filtered['tic'] = oap_filtered['permno'].map(permno_unique)\n",
    "\n",
    "    oap_filtered['date'] = pd.to_datetime(oap_filtered['yyyymm'], format='%Y%m')\n",
    "    oap_filtered.rename(columns={'tic':'ticker'}, inplace=True)\n",
    "    oap_filtered.drop(['permno', 'yyyymm'], axis=1, inplace=True)\n",
    "    oap_filtered.set_index(['ticker', 'date'], inplace=True)\n",
    "    oap_filtered.sort_index(level=['ticker', 'date'], inplace=True)\n",
    "    \n",
    "    # Find overlapping tickers\n",
    "    current_tickers = read_ticker(get_load_data_large_dir() / 'tickers_to_train_fundamental.csv')\n",
    "    oap_tickers = get_ticker_idx(oap_filtered)\n",
    "    overlapping_tickers = list(set(oap_tickers) & set(current_tickers))\n",
    "\n",
    "    # Filter DataFrame based on overlapping tickers\n",
    "    oap_filtered = oap_filtered[oap_filtered.index.get_level_values('ticker').isin(overlapping_tickers)]\n",
    "    \n",
    "    export_ticker(oap_filtered, get_load_data_large_dir() / 'tickers_to_train_open.csv')\n",
    "    oap_filtered.to_parquet(get_load_data_parquet_dir() / 'data_open_asset.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001c2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_open_asset_pricing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59795b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_asset = pd.read_parquet(get_load_data_parquet_dir() / 'data_open_asset.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d15c03",
   "metadata": {},
   "source": [
    "# Dividend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "19cec509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dividend():\n",
    "    dividend = pd.read_csv(get_load_data_large_dir() / 'dividend.csv')\n",
    "    dividend = dividend.drop(['PERMNO'], axis=1)\n",
    "    dividend.columns = ['date', 'ticker', 'divdecdt', 'divpaydt', 'divrecdt', 'distcode', 'divpay']\n",
    "    dividend['date'] = pd.to_datetime(dividend['date'])\n",
    "    dividend['divdecdt'] = pd.to_datetime(dividend['divdecdt'])\n",
    "    dividend['divpaydt'] = pd.to_datetime(dividend['divpaydt'])\n",
    "    dividend['divrecdt'] = pd.to_datetime(dividend['divrecdt'])\n",
    "    dividend = dividend.set_index(['ticker', 'date']).sort_index(level=['ticker', 'date'])\n",
    "    dividend = dividend[dividend.index.get_level_values('ticker').notna()]\n",
    "\n",
    "    mask = ~dividend['distcode'].astype(str).str.startswith('12')\n",
    "    dividend[mask] = np.nan\n",
    "    dividend.to_parquet(get_load_data_parquet_dir() / 'data_dividend.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "db2016ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dividend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "02745ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dividend = pd.read_parquet(get_load_data_parquet_dir() / 'data_dividend.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ffd13a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e49e7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca_return_test():\n",
    "    # Read in price data and set time frame and remove data with less than 2 years length of data (same data as create_factor.py)\n",
    "    price_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_price.parquet.brotli')\n",
    "    ticker = read_ticker(get_load_data_large_dir() / 'tickers_to_train_fundamental.csv')\n",
    "    price_data = set_timeframe(price_data, '2002-01-01', '2023-01-01')\n",
    "    price_data = price_data.loc[ticker]\n",
    "\n",
    "    # Create returns and convert ticker index to columns\n",
    "    price_data = create_return(price_data, windows=[1])\n",
    "    ret = price_data[[f'RET_01']]\n",
    "    ret = ret['RET_01'].unstack('ticker')\n",
    "    ret.iloc[0] = ret.iloc[0].fillna(0)\n",
    "\n",
    "    # Execute Rolling PCA\n",
    "    window_size=60\n",
    "    num_components=5\n",
    "    pca_return = rolling_pca(data=ret, window_size=window_size, num_components=num_components, name='Return')\n",
    "    pca_return.to_parquet(get_load_data_parquet_dir() / 'data_pca_ret_test.parquet.brotli', compression='brotli')\n",
    "\n",
    "def create_all_rf_test():\n",
    "    etf_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_etf.parquet.brotli')\n",
    "    fama_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_fama.parquet.brotli')\n",
    "    pca_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_pca_ret_test.parquet.brotli')\n",
    "    macro_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_macro.parquet.brotli')\n",
    "    all_rf = pd.concat([etf_data, fama_data, pca_data, macro_data], axis=1)\n",
    "    all_rf = set_timeframe(all_rf, '2002-01-01', '2023-01-01')\n",
    "    fama_data = set_timeframe(fama_data, '2002-01-01', '2023-01-01')\n",
    "    # Execute Rolling PCA\n",
    "    window_size=60\n",
    "    num_components=5\n",
    "    pca_rf = rolling_pca(data=all_rf, window_size=window_size, num_components=num_components, name='RF')\n",
    "    # Add risk-free rate\n",
    "    pca_rf = pd.concat([pca_rf, fama_data['RF']], axis=1)    \n",
    "    pca_rf.to_parquet(get_load_data_parquet_dir() / 'data_all_rf_test.parquet.brotli', compression = 'brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pca_return_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d033c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_all_rf_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b13d1",
   "metadata": {},
   "source": [
    "# Fund Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "19927951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fund_ind():\n",
    "    fund_ind = pd.read_csv(get_load_data_large_dir() / 'fund_ind.csv')\n",
    "\n",
    "    def convert_to_float(cell):\n",
    "        if isinstance(cell, str) and '%' in cell:\n",
    "            return float(cell.replace('%', '')) / 100\n",
    "        return float(cell)\n",
    "\n",
    "    def connect(s):\n",
    "        return '_'.join(word for word in s.split() if word)\n",
    "\n",
    "    fund_ind['public_date'] = pd.to_datetime(fund_ind['public_date'])\n",
    "    fund_ind = fund_ind.rename(columns={'public_date': 'date'}).set_index(['date', 'gicdesc'])\n",
    "    fund_ind = fund_ind.drop(['NFIRM'], axis=1)\n",
    "    fund_ind = fund_ind.fillna(0)\n",
    "\n",
    "    collect = []\n",
    "    for ind, df in fund_ind.groupby('gicdesc'):\n",
    "        ind = connect(ind)\n",
    "        df = df.applymap(convert_to_float)\n",
    "        # Execute Rolling PCA\n",
    "        window_size=5 # 3 months\n",
    "        num_components=5\n",
    "        pca_fund_ind = rolling_pca(data=df, window_size=window_size, num_components=num_components, name=f'FI_{ind}')\n",
    "        pca_fund_ind = pca_fund_ind.reset_index('gicdesc').drop('gicdesc', axis=1)\n",
    "        collect.append(pca_fund_ind)\n",
    "\n",
    "    fund_ind = pd.concat(collect, axis=1)\n",
    "    fund_ind.to_parquet(get_load_data_parquet_dir() / 'data_fund_ind.parquet.brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8432b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fund_ind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3c9297f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_ind = pd.read_parquet(get_load_data_parquet_dir() / 'data_fund_ind.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96315b9a",
   "metadata": {},
   "source": [
    "# Fund Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7900cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fund_raw():\n",
    "    fund_raw = pd.read_csv(get_load_data_large_dir() / 'fund_raw.csv')\n",
    "\n",
    "    fund_raw = fund_raw.drop(['gvkey', 'fyearq', 'indfmt', 'consol', 'popsrc',\n",
    "                              'datafmt', 'curcdq', 'datacqtr', 'datafqtr', 'costat'], axis=1)\n",
    "\n",
    "    fund_raw['datadate'] = pd.to_datetime(fund_raw['datadate'])\n",
    "\n",
    "    fund_raw = fund_raw.rename(columns={'datadate': 'date', 'tic': 'ticker'}).set_index(['ticker', 'date'])\n",
    "\n",
    "    fund_raw = fund_raw.sort_index(level=['ticker', 'date'])\n",
    "\n",
    "    fund_raw = fund_raw.drop(columns=fund_raw.columns[fund_raw.isna().sum() > len(fund_raw) / 3])\n",
    "    \n",
    "    fund_q = fund_raw[['fqtr']]\n",
    "    fund_q = fund_q.fillna(-1)\n",
    "    fund_q = fund_q.astype(int)\n",
    "\n",
    "    fund_raw = fund_raw.drop('fqtr', axis=1)\n",
    "    fund_raw = fund_raw.pct_change()\n",
    "\n",
    "    date_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_date.parquet.brotli')\n",
    "    tickers = read_ticker(get_load_data_large_dir() / 'tickers_to_train_fundamental.csv')\n",
    "    date_data = set_timeframe(date_data, '2004-01-01', '2023-06-01')\n",
    "\n",
    "#     fund_raw = pd.merge(date_data.loc[tickers], fund_raw, left_index=True, right_index=True, how='left')\n",
    "#     fund_raw = fund_raw.loc[~fund_raw.index.duplicated(keep='first')]\n",
    "#     fund_raw = fund_raw.ffill()\n",
    "    \n",
    "#     fund_q = pd.merge(date_data.loc[tickers], fund_q, left_index=True, right_index=True, how='left')\n",
    "#     fund_q = fund_q.loc[~fund_q.index.duplicated(keep='first')]\n",
    "#     fund_q = fund_q.ffill()\n",
    "\n",
    "#     price_data = pd.read_parquet(get_load_data_parquet_dir() / 'data_price.parquet.brotli')\n",
    "#     fund_raw = pd.merge(fund_raw, price_data.Close.loc[tickers], left_index=True, right_index=True, how='left')\n",
    "#     fund_raw = fund_raw.loc[~fund_raw.index.duplicated(keep='first')]\n",
    "#     fund_raw.iloc[:, :-1] = fund_raw.iloc[:, :-1].div(fund_raw.Close, axis=0)\n",
    "#     fund_raw = fund_raw.drop(['Close'], axis=1)\n",
    "    fund_raw = fund_raw.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    fund_q.to_parquet(get_load_data_parquet_dir() / 'data_fund_q.parquet.brotli')\n",
    "    fund_raw.to_parquet(get_load_data_parquet_dir() / 'data_fund_raw.parquet.brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "87d525f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fund_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "99672861",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_q = pd.read_parquet(get_load_data_parquet_dir() / 'data_fund_q.parquet.brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "91dfd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_raw = pd.read_parquet(get_load_data_parquet_dir() / 'data_fund_raw.parquet.brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74da4c",
   "metadata": {},
   "source": [
    "# Bubbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddf66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3f22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e07f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd8d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e11b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49d1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantPycharm",
   "language": "python",
   "name": "quantpycharm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
