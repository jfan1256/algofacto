{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c991b18c-3c44-44be-8c44-d9786a5d53a2",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a50f8d-78cc-4f7b-8eb0-f695af63ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import polars as pl\n",
    "import wrds\n",
    "from datetime import date\n",
    "\n",
    "from functions.utils.func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccea862-7294-4838-bb94-f494888dc8bf",
   "metadata": {},
   "source": [
    "### Establish First Connection to WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318cde3c-eb44-485b-a37f-cafd529509a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = wrds.Connection(wrds_username='jofan23')\n",
    "# db.create_pgpass_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e00a407-bfa9-4954-b1b1-b767fe86dea4",
   "metadata": {},
   "source": [
    "# Present Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6339e50-fa17-4887-8256-fbe3c7428463",
   "metadata": {},
   "outputs": [],
   "source": [
    "live = True\n",
    "current_date = date.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9746f2-ec7d-45ca-85f6-7813643b1cf3",
   "metadata": {},
   "source": [
    "# Link Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4988ad0-62e6-4179-8a95-08c188d8990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read in linking table\n",
      "Loading library list...\n",
      "Done\n",
      "Rename columns\n",
      "Export link table\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_link = f\"\"\"\n",
    "    SELECT a.gvkey, a.conm, a.tic, a.cusip, a.cik, a.sic, a.naics, b.linkprim,\n",
    "           b.linktype, b.liid, b.lpermno, b.lpermco, b.linkdt, b.linkenddt\n",
    "    FROM comp.names as a\n",
    "    INNER JOIN crsp.ccmxpf_lnkhist as b\n",
    "    ON a.gvkey = b.gvkey\n",
    "    WHERE b.linktype in ('LC', 'LU')\n",
    "    AND b.linkprim in ('P', 'C')\n",
    "    ORDER BY a.gvkey;\n",
    "\"\"\"\n",
    "\n",
    "# Read in linking table\n",
    "print(\"Read in linking table...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "link = db.raw_sql(sql_link)\n",
    "db.close()\n",
    "\n",
    "# Rename columns\n",
    "print(\"Rename columns...\")\n",
    "link = link.rename(columns={\n",
    "    'linkdt': 'timeLinkStart_d',\n",
    "    'linkenddt': 'timeLinkEnd_d',\n",
    "    'lpermno': 'permno',\n",
    "    'tic': 'ticker'\n",
    "})\n",
    "\n",
    "link['permno'] = link['permno'].astype(int)\n",
    "\n",
    "# Export link table\n",
    "print(\"Export link table...\")\n",
    "link.to_parquet(get_parquet_dir(live) / 'data_link.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3007e0-f5d8-4cdb-bf11-68e799b13f5a",
   "metadata": {},
   "source": [
    "# Compustat Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e5166f-b4e0-4275-9640-951156fe5452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read in Compustat Annual\n",
      "Loading library list...\n",
      "Done\n",
      "Read in link table\n",
      "Merge link table and Compustat Annual\n",
      "Drop rows based on condition\n",
      "Extract 6 digits from CUSIP\n",
      "Replacing missing values\n",
      "Shift data forward by 6 months\n",
      "Convert index from annually to monthly\n",
      "Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\n",
      "Set index and remove duplicate indices\n",
      "Export data\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_compustat_annual = f\"\"\"\n",
    "    SELECT a.gvkey, a.datadate, a.conm, a.fyear, a.tic, a.cusip, a.naicsh, a.sich, \n",
    "    a.aco, a.act, a.ajex, a.am, a.ao, a.ap, a.at, a.capx, a.ceq, a.ceqt, a.che, a.cogs,\n",
    "    a.csho, a.cshrc, a.dcpstk, a.dcvt, a.dlc, a.dlcch, a.dltis, a.dltr,\n",
    "    a.dltt, a.dm, a.dp, a.drc, a.drlt, a.dv,a.dvc,a.dvp,a.dvpa,a.dvpd,\n",
    "    a.dvpsx_c, a.dvt, a.ebit, a.ebitda, a.emp, a.epspi, a.epspx, a.fatb, a.fatl,\n",
    "    a.ffo, a.fincf, a.fopt, a.gdwl, a.gdwlia, a.gdwlip, a.gwo, a.ib, a.ibcom,\n",
    "    a.intan, a.invt, a.ivao, a.ivncf, a.ivst, a.lco, a.lct, a.lo ,a.lt, a.mib,\n",
    "    a.msa, a.ni, a.nopi, a.oancf, a.ob, a.oiadp, a.oibdp, a.pi, a.ppenb, a.ppegt,\n",
    "    a.ppenls, a.ppent, a.prcc_c, a.prcc_f, a.prstkc, a.prstkcc, a.pstk, a.pstkl, a.pstkrv,\n",
    "    a.re, a.rect, a.recta, a.revt, a.sale, a.scstkc, a.seq, a.spi, a.sstk,\n",
    "    a.tstkp, a.txdb, a.txdi, a.txditc, a.txfo, a.txfed, a.txp, a.txt,\n",
    "    a.wcap, a.wcapch, a.xacc, a.xad, a.xint, a.xrd, a.xpp, a.xsga\n",
    "    FROM COMP.FUNDA as a\n",
    "    WHERE a.consol = 'C'\n",
    "    AND a.popsrc = 'D'\n",
    "    AND a.datafmt = 'STD'\n",
    "    AND a.curcd = 'USD'\n",
    "    AND a.indfmt = 'INDL'\n",
    "    AND a.datadate BETWEEN '2005-01-01' AND '{current_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Read in Compustat Annual\n",
    "print(\"Read in Compustat Annual...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "compustat_annual = db.raw_sql(sql_compustat_annual)\n",
    "db.close()\n",
    "\n",
    "# Read in link table\n",
    "print(\"Read in link table...\")\n",
    "link_table = pd.read_parquet(get_parquet_dir(live) / 'data_link.parquet.brotli')\n",
    "link_table = link_table.drop(['cusip', 'conm'], axis=1)\n",
    "\n",
    "# Merge link table and Compustat Annual\n",
    "print(\"Merge link table and Compustat Annual...\")\n",
    "annual = compustat_annual.merge(link_table, on='gvkey', how='inner')\n",
    "\n",
    "# Drop rows based on condition\n",
    "print(\"Drop rows based on condition...\")\n",
    "annual = annual.dropna(subset=['at', 'prcc_c', 'ni'])\n",
    "\n",
    "# Extract 6 digits from CUSIP\n",
    "print(\"Extract 6 digits from CUSIP...\")\n",
    "annual['cnum'] = annual['cusip'].str[:6]\n",
    "\n",
    "# Replacing missing values\n",
    "print(\"Replacing missing values...\")\n",
    "annual['dr'] = annual.apply(lambda row: row['drc'] + row['drlt'] if pd.notna(row['drc']) and pd.notna(row['drlt']) else (row['drc'] if pd.notna(row['drc']) else (row['drlt'] if pd.notna(row['drlt']) else None)), axis=1)\n",
    "annual.loc[(annual['dcpstk'] > annual['pstk']) & pd.notna(annual['dcpstk']) & pd.notna(annual['pstk']) & pd.isna(annual['dcvt']), 'dc'] = annual['dcpstk'] - annual['pstk']\n",
    "annual.loc[pd.isna(annual['pstk']) & pd.notna(annual['dcpstk']) & pd.isna(annual['dcvt']), 'dc'] = annual['dcpstk']\n",
    "annual.loc[pd.isna(annual['dc']), 'dc'] = annual['dcvt']\n",
    "annual['xint0'] = annual['xint'].fillna(0)\n",
    "annual['xsga0'] = annual['xsga'].fillna(0)\n",
    "annual['xad0'] = annual.apply(lambda row: 0 if row['xad'] < 0 else row['xad'], axis=1)\n",
    "vars_list = ['nopi', 'dvt', 'ob', 'dm', 'dc', 'aco', 'ap', 'intan', 'ao', 'lco', 'lo', 'rect', 'invt', 'drc', 'spi', 'gdwl', 'che', 'dp', 'act', 'lct', 'tstkp', 'dvpa', 'scstkc', 'sstk', 'mib', 'ivao', 'prstkc', 'prstkcc', 'txditc', 'ivst']\n",
    "for var in vars_list:\n",
    "    annual[var].fillna(0, inplace=True)\n",
    "\n",
    "# Shift data forward by 6 months\n",
    "print(\"Shift data forward by 6 months...\")\n",
    "annual['date'] = pd.to_datetime(annual['datadate']).dt.to_period('M') + 6\n",
    "\n",
    "# Convert index from annually to monthly\n",
    "print(\"Convert index from annually to monthly...\")\n",
    "annual = annual.reindex(annual.index.repeat(12))\n",
    "annual['tempTime'] = annual.groupby(['gvkey', 'date']).cumcount()\n",
    "annual['date'] += annual['tempTime']\n",
    "annual = annual.drop(columns=['tempTime'])\n",
    "\n",
    "# Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\n",
    "print(\"Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\")\n",
    "annual.date = annual.date.dt.to_timestamp(\"M\")\n",
    "annual = annual.drop('datadate', axis=1)\n",
    "\n",
    "# Set index and remove duplicate indices\n",
    "print(\"Set index and remove duplicate indices...\")\n",
    "annual = annual.set_index(['permno', 'date'])\n",
    "annual = annual.sort_index(level=['permno', 'date'])\n",
    "annual = annual[~annual.index.duplicated(keep='first')]\n",
    "\n",
    "# Export data\n",
    "print(\"Export data\")\n",
    "annual.to_parquet(get_parquet_dir(live) / 'data_fund_raw_a.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cbd5aa-e4d9-4178-b2a1-f6d04112f77b",
   "metadata": {},
   "source": [
    "# Compustat Quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23607a83-f898-4a5c-ba7a-4cdcb6998fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read In Compustat Quarterly\n",
      "Loading library list...\n",
      "Done\n",
      "Read in link table\n",
      "Merge link table and Compustat Annual\n",
      "Keep only the most recent data for each fiscal quarter\n",
      "Convert to datetime\n",
      "Shift data 3 months forward\n",
      "Compute month difference\n",
      "Keep most recent data\n",
      "Create extra yearly columns\n",
      "Convert index from quarterly to monthly\n",
      "Sort values and keep most recent data\n",
      "Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\n",
      "Convert data to numerical format (exclude columns that are not numerical format)\n",
      "Forward fill yearly data\n",
      "Export data\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_compustat_quarterly = f\"\"\"\n",
    "    SELECT a.gvkey, a.datadate, a.fyearq, a.fqtr, a.datacqtr, a.datafqtr, a.acoq,\n",
    "\ta.actq, a.ajexq, a.apq, a.atq, a.ceqq, a.cheq, a.cogsq, a.cshoq, a.cshprq,\n",
    "\ta.dlcq, a.dlttq, a.dpq, a.drcq, a.drltq, a.dvpsxq, a.dvpq, a.dvy, a.epspiq, a.epspxq, a.fopty,\n",
    "\ta.gdwlq, a.ibq, a.invtq, a.intanq, a.ivaoq, a.lcoq, a.lctq, a.loq, a.ltq, a.mibq,\n",
    "\ta.niq, a.oancfy, a.oiadpq, a.oibdpq, a.piq, a.ppentq, a.ppegtq, a.prstkcy, a.prccq,\n",
    "\ta.pstkq, a.rdq, a.req, a.rectq, a.revtq, a.saleq, a.seqq, a.sstky, a.txdiq,\n",
    "\ta.txditcq, a.txpq, a.txtq, a.xaccq, a.xintq, a.xsgaq, a.xrdq, a.capxy\n",
    "    FROM COMP.FUNDQ as a\n",
    "\tWHERE a.consol = 'C'\n",
    "\tAND a.popsrc = 'D'\n",
    "\tAND a.datafmt = 'STD'\n",
    "\tAND a.curcdq = 'USD'\n",
    "\tAND a.indfmt = 'INDL'\n",
    "    AND a.datadate BETWEEN '2005-01-01' AND '{current_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Read in Compustat Quarterly\n",
    "print(\"Read In Compustat Quarterly...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "compustat_quarterly = db.raw_sql(sql_compustat_quarterly)\n",
    "db.close()\n",
    "\n",
    "# Read in link table\n",
    "print(\"Read in link table...\")\n",
    "link_table = pd.read_parquet(get_parquet_dir(live) / 'data_link.parquet.brotli')\n",
    "link_table = link_table.drop(['cusip', 'conm'], axis=1)\n",
    "\n",
    "# Merge link table and Compustat Annual\n",
    "print(\"Merge link table and Compustat Annual...\")\n",
    "quarterly = compustat_quarterly.merge(link_table, on='gvkey', how='inner')\n",
    "\n",
    "\n",
    "# Keep only the most recent data for each fiscal quarter\n",
    "print(\"Keep only the most recent data for each fiscal quarter...\")\n",
    "quarterly = quarterly.sort_values(by=['gvkey', 'fyearq', 'fqtr', 'datadate'])\n",
    "quarterly = quarterly.groupby(['gvkey', 'fyearq', 'fqtr']).last().reset_index()\n",
    "\n",
    "# Convert to datetime\n",
    "print(\"Convert to datetime...\")\n",
    "quarterly['datadate'] = pd.to_datetime(quarterly['datadate'])\n",
    "quarterly['rdq'] = pd.to_datetime(quarterly['rdq'])\n",
    "\n",
    "# Shift data 3 months forward\n",
    "print(\"Shift data 3 months forward...\")\n",
    "quarterly['time_avail_m'] = (quarterly['datadate'] + pd.DateOffset(months=3)).dt.to_period('M')\n",
    "quarterly.loc[(~quarterly['rdq'].isnull()) & (quarterly['rdq'].dt.to_period('M') > quarterly['time_avail_m']), 'time_avail_m'] = quarterly['rdq'].dt.to_period('M')\n",
    "\n",
    "# Compute month difference\n",
    "print(\"Compute month difference...\")\n",
    "month_diff = (quarterly['rdq'] - quarterly['datadate']).dt.days // 30\n",
    "quarterly = quarterly.drop(quarterly[(month_diff > 6) & ~quarterly['rdq'].isnull()].index)\n",
    "quarterly = quarterly.sort_values(by=['gvkey', 'time_avail_m', 'datadate'])\n",
    "\n",
    "# Keep most recent data\n",
    "print(\"Keep most recent data...\")\n",
    "quarterly = quarterly.groupby(['gvkey', 'time_avail_m']).last().reset_index()\n",
    "\n",
    "# Create extra yearly columns\n",
    "print(\"Create extra yearly columns...\")\n",
    "for col in ['sstky', 'prstkcy', 'oancfy', 'fopty']:\n",
    "    grouped = quarterly.groupby(['gvkey', 'fyearq'])[col]\n",
    "    condition = quarterly['fqtr'] == 1\n",
    "    new_values = np.where(condition, quarterly[col], quarterly[col] - grouped.shift(1))\n",
    "    quarterly[col + 'q'] = new_values\n",
    "    \n",
    "# Convert index from quarterly to monthly\n",
    "print(\"Convert index from quarterly to monthly...\")\n",
    "quarterly = quarterly.loc[quarterly.index.repeat(3)]\n",
    "quarterly['tempTimeAvailM'] = quarterly['time_avail_m']\n",
    "quarterly = quarterly.sort_values(by=['gvkey', 'tempTimeAvailM'])\n",
    "quarterly['time_avail_m'] = quarterly.groupby(['gvkey', 'tempTimeAvailM']).cumcount() + quarterly['time_avail_m']\n",
    "\n",
    "# Sort values\n",
    "print(\"Sort values and keep most recent data...\")\n",
    "quarterly = quarterly.sort_values(by=['gvkey', 'time_avail_m', 'datadate'])\n",
    "# Keep most recent data\n",
    "quarterly = quarterly.groupby(['gvkey', 'time_avail_m']).last().reset_index()\n",
    "quarterly = quarterly.drop(columns=['tempTimeAvailM'])\n",
    "quarterly = quarterly.rename(columns={'datadate': 'datadateq', 'time_avail_m':'date'})\n",
    "\n",
    "# Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\n",
    "print(\"Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)...\")\n",
    "quarterly.date = quarterly.date.dt.to_timestamp(\"M\")\n",
    "quarterly = quarterly.set_index(['permno', 'date'])\n",
    "\n",
    "# Convert data to numerical format (exclude columns that are not numerical format)\n",
    "print(\"Convert data to numerical format (exclude columns that are not numerical format)...\")\n",
    "numeric_cols = quarterly.select_dtypes(include=['number']).columns\n",
    "quarterly[numeric_cols] = quarterly[numeric_cols].astype(float)\n",
    "non_numeric_cols = quarterly.select_dtypes(exclude=['number']).columns\n",
    "quarterly_numeric = quarterly[numeric_cols]\n",
    "quarterly_numeric = quarterly_numeric.sort_index(level=['permno', 'date'])\n",
    "\n",
    "# Forward fill yearly data\n",
    "print(\"Forward fill yearly data...\")\n",
    "cols_to_fill = [col for col in quarterly_numeric.columns if col.endswith('y')]\n",
    "quarterly_numeric[cols_to_fill] = quarterly_numeric[cols_to_fill].ffill()\n",
    "\n",
    "# Export data\n",
    "print(\"Export data...\")\n",
    "quarterly_numeric.to_parquet(get_parquet_dir(live) / 'data_fund_raw_q.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929c515-c008-4284-9aff-0c0b437737b2",
   "metadata": {},
   "source": [
    "# Compustat Pension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c93b2-8cf3-4b47-bf1a-43c58867dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read in Pension Annual\n",
      "Loading library list...\n",
      "Done\n",
      "Drop duplicate indices\n",
      "Convert to datetime and set index\n",
      "Shift everything 1 year forward\n",
      "Export data\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_compustat_pension = f\"\"\"\n",
    "    SELECT a.gvkey, a.datadate, a.paddml, a.pbnaa, a.pbnvv, a.pbpro, \n",
    "\t       a.pbpru, a.pcupsu, a.pplao, a.pplau\n",
    "    FROM COMP.ACO_PNFNDA as a\n",
    "\tWHERE a.consol = 'C'\n",
    "\tAND a.popsrc = 'D'\n",
    "\tAND a.datafmt = 'STD'\n",
    "\tAND a.indfmt = 'INDL'\n",
    "    AND a.datadate BETWEEN '2005-01-01' AND '{current_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Read in Pension Annual\n",
    "print(\"Read in Pension Annual...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "pension = db.raw_sql(sql_compustat_pension)\n",
    "db.close()\n",
    "\n",
    "# Drop duplicate indices\n",
    "print(\"Drop duplicate indices...\")\n",
    "pension = pension.sort_values(by=['gvkey', 'datadate'])\n",
    "pension = pension.groupby(['gvkey', 'datadate']).last().reset_index()\n",
    "\n",
    "# Convert to datetime and set index\n",
    "print(\"Convert to datetime and set index...\")\n",
    "pension['datadate'] = pd.to_datetime(pension['datadate'])\n",
    "pension = pension.rename(columns = {'datadate': 'date', 'tic': 'ticker'})\n",
    "pension = pension.set_index('date')\n",
    "\n",
    "# Shift everything 1 year forward\n",
    "print(\"Shift everything 1 year forward...\")\n",
    "for col in pension.columns:\n",
    "    if col != 'gvkey' or col != 'indfmt' or col != 'datafmt' or col != 'consol' or col != 'popsrc' or col != 'ticker':\n",
    "        pension[col] = pension.groupby('gvkey')[col].shift(1)\n",
    "\n",
    "# Export data\n",
    "print(\"Export data\")\n",
    "pension.to_parquet(get_parquet_dir(live) / 'data_pension.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad1b5e-9f7a-4e62-900d-c6e418c5e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pension"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algofacto",
   "language": "python",
   "name": "algofacto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
