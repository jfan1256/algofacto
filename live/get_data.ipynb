{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c991b18c-3c44-44be-8c44-d9786a5d53a2",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a50f8d-78cc-4f7b-8eb0-f695af63ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import polars as pl\n",
    "import wrds\n",
    "from fredapi import Fred\n",
    "from datetime import date\n",
    "\n",
    "from functions.utils.func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccea862-7294-4838-bb94-f494888dc8bf",
   "metadata": {},
   "source": [
    "### Establish First Connection to WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318cde3c-eb44-485b-a37f-cafd529509a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = wrds.Connection(wrds_username='jofan23')\n",
    "# db.create_pgpass_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e00a407-bfa9-4954-b1b1-b767fe86dea4",
   "metadata": {},
   "source": [
    "# Present Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6339e50-fa17-4887-8256-fbe3c7428463",
   "metadata": {},
   "outputs": [],
   "source": [
    "live = True\n",
    "update_stock_list = True\n",
    "current_date = date.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9746f2-ec7d-45ca-85f6-7813643b1cf3",
   "metadata": {},
   "source": [
    "# Link Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4988ad0-62e6-4179-8a95-08c188d8990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read in linking table...\n",
      "Loading library list...\n",
      "Done\n",
      "Rename columns...\n",
      "Drop rows where the 'ticker' column has numbers...\n",
      "Remove any non-alphabetic characters from the 'ticker' column...\n",
      "Remove duplicate permno, gvkey, and ticker and keep the most recent based off timeLinkEnd_d...\n",
      "Export link table...\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_link = f\"\"\"\n",
    "    SELECT a.gvkey, a.conm, a.tic, a.cusip, a.cik, a.sic, a.naics, b.linkprim,\n",
    "           b.linktype, b.liid, b.lpermno, b.lpermco, b.linkdt, b.linkenddt\n",
    "    FROM comp_na_daily_all.names as a\n",
    "    INNER JOIN crsp.ccmxpf_lnkhist as b\n",
    "    ON a.gvkey = b.gvkey\n",
    "    WHERE b.linktype in ('LC', 'LU')\n",
    "    AND b.linkprim in ('P', 'C')\n",
    "    ORDER BY a.gvkey;\n",
    "\"\"\"\n",
    "\n",
    "# Read in linking table\n",
    "print(\"Read in linking table...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "link_table = db.raw_sql(sql_link)\n",
    "db.close()\n",
    "\n",
    "# Rename columns\n",
    "print(\"Rename columns...\")\n",
    "link_table = link_table.rename(columns={\n",
    "    'linkdt': 'timeLinkStart_d',\n",
    "    'linkenddt': 'timeLinkEnd_d',\n",
    "    'lpermno': 'permno',\n",
    "    'tic': 'ticker'\n",
    "})\n",
    "\n",
    "# Drop rows where the 'ticker' column has numbers\n",
    "print(\"Drop rows where the 'ticker' column has numbers...\")\n",
    "link_table = link_table[~link_table['ticker'].str.contains('\\d', regex=True)]\n",
    "\n",
    "# Remove any non-alphabetic characters from the 'ticker' column\n",
    "print(\"Remove any non-alphabetic characters from the 'ticker' column...\")\n",
    "link_table['ticker'] = link_table['ticker'].str.replace('[^A-Za-z]', '', regex=True)\n",
    "link_table['permno'] = link_table['permno'].astype(int)\n",
    "\n",
    "# Remove duplicate permno\n",
    "print(\"Remove duplicate permno, gvkey, and ticker and keep the most recent based off timeLinkEnd_d...\")\n",
    "link_table['timeLinkEnd_d'] = pd.to_datetime(link_table['timeLinkEnd_d'].replace(pd.NaT, current_date))\n",
    "link_table = link_table.sort_values(by=['ticker', 'timeLinkEnd_d'])\n",
    "link_table = link_table.drop_duplicates(subset='ticker', keep='last')\n",
    "link_table = link_table.drop_duplicates(subset='permno', keep='last')\n",
    "link_table = link_table.drop_duplicates(subset='gvkey', keep='last')\n",
    "\n",
    "# Export link table\n",
    "print(\"Export link table...\")\n",
    "link_table.to_parquet(get_parquet_dir(live) / 'data_link.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59994b-2773-4b21-b551-a1bc74b19ebb",
   "metadata": {},
   "source": [
    "# CRSP Daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a6387-2d47-4848-8de0-42c001aad325",
   "metadata": {},
   "source": [
    "### This will be used to determine what stocks to trade on an annual basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aabf7137-acd8-4aa8-8869-74fa4d9c4b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop permno/date pairs that have multiple tickers...\n",
      "Exporting stock list...\n",
      "Number of stocks: 1110\n"
     ]
    }
   ],
   "source": [
    "if update_stock_list:\n",
    "    # Read in CRSP dataset\n",
    "    print('Read in CRSP dataset')\n",
    "    crsp = pd.read_csv(get_large_dir(live) / 'crsp_price.csv')\n",
    "    \n",
    "    # Rename Columns\n",
    "    print('Rename columns...')\n",
    "    crsp.columns = crsp.columns.str.lower()\n",
    "    crsp = crsp.rename(columns={'prc':'Close', 'bid':'High', 'ask':'Low', 'openprc':'Open', 'shrout':'outstanding', 'vol':'Volume', 'cfacpr':'adj_price'})\n",
    "    \n",
    "    # Adjust closing price\n",
    "    print('Adjusting Close Price...')\n",
    "    crsp['Close'] = crsp['Close']/crsp['adj_price']\n",
    "    \n",
    "    # Set and sort index\n",
    "    print('Set and sort indices...')\n",
    "    crsp.date = pd.to_datetime(crsp.date)\n",
    "    crsp = crsp.set_index(['permno', 'date'])\n",
    "    crsp = crsp.sort_index(level=['permno', 'date'])\n",
    "    \n",
    "    # Remove duplicate indices and replace all infinity with nan\n",
    "    print('Remove duplicate indices and infinity...')\n",
    "    crsp = crsp[~crsp.index.duplicated(keep='first')]\n",
    "    crsp = crsp.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Remove stocks that have more than 1 NAN values in their Closing price column\n",
    "    # Stocks that get delisted have 1 row of NAN values as their last row\n",
    "    # Stocks that switch ticker (WM to COOP: 81593) have rows of NAN valuescap = cap.dropna(subset='Close')\n",
    "    # Afterwards, drop all rows that have NAN values in Close (every delisted permno stock only has 1 NAN in Close now)\n",
    "    print('Remove stocks with NAN...')\n",
    "    nan_counts = crsp.groupby('permno')['Close'].apply(lambda x: x.isna().sum())\n",
    "    valid_permnos = nan_counts[nan_counts <= 1].index.tolist()\n",
    "    crsp = crsp[crsp.index.get_level_values('permno').isin(valid_permnos)]\n",
    "    crsp = crsp.dropna(subset='Close')\n",
    "    \n",
    "    # Remove dates in stocks that have a negative closing price\n",
    "    crsp = crsp[crsp['Close'] >= 0]\n",
    "    \n",
    "    # Remove stocks that do not have at least 3 years worth of year data\n",
    "    print('Set length to 3 years...')\n",
    "    crsp = set_length(crsp, 3)\n",
    "    \n",
    "    # Drop permno that do not have over 5B market cap\n",
    "    print(\"Drop permno that do not have over 5B market cap...\")\n",
    "    crsp['market_cap'] = crsp['Close'] * crsp['outstanding'] * 1000\n",
    "    avg_cap = crsp.groupby('permno')['market_cap'].mean()\n",
    "    above_cap = avg_cap[avg_cap > 5_000_000_000].index\n",
    "    crsp = crsp[crsp.index.get_level_values('permno').isin(above_cap)]\n",
    "\n",
    "    # Drop permno/date pairs that have multiple tickers\n",
    "    print(\"Drop permno/date pairs that have multiple tickers...\")\n",
    "    ticker_counts = crsp.groupby('permno')['ticker'].nunique()\n",
    "    to_drop_permnos = ticker_counts[ticker_counts > 1].index\n",
    "    crsp = crsp[~crsp.index.get_level_values('permno').isin(to_drop_permnos)]\n",
    "    \n",
    "    # Export list of stocks\n",
    "    print('Exporting stock list...')\n",
    "    print(f'Number of stocks: {len(get_stock_idx(crsp))}')\n",
    "    export_stock(crsp, get_large_dir(live) / 'permno_crsp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cbd5aa-e4d9-4178-b2a1-f6d04112f77b",
   "metadata": {},
   "source": [
    "# Compustat Quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23607a83-f898-4a5c-ba7a-4cdcb6998fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read In Compustat Quarterly...\n",
      "Loading library list...\n",
      "Done\n",
      "Read in link table...\n",
      "Merge link table and Compustat Quarterly...\n",
      "Keep only the most recent data for each fiscal quarter...\n",
      "Convert to datetime...\n",
      "Shift data 3 months forward...\n",
      "Compute month difference...\n",
      "Keep most recent data...\n",
      "Create extra yearly columns...\n",
      "Convert index from quarterly to monthly...\n",
      "Sort values and keep most recent data...\n",
      "Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)...\n",
      "Read in CRSP stock list...\n",
      "Exporting stock list for live trading...\n",
      "Number of stocks: 856\n",
      "Export ticker list...\n",
      "Convert data to numerical format (exclude columns that are not numerical format)...\n",
      "Forward fill yearly data...\n",
      "Export data...\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_compustat_quarterly = f\"\"\"\n",
    "    SELECT a.gvkey, a.datadate, a.fyearq, a.fqtr, a.datacqtr, a.datafqtr, a.acoq,\n",
    "\ta.actq, a.ajexq, a.apq, a.atq, a.ceqq, a.cheq, a.cogsq, a.cshoq, a.cshprq,\n",
    "\ta.dlcq, a.dlttq, a.dpq, a.drcq, a.drltq, a.dvpsxq, a.dvpq, a.dvy, a.epspiq, a.epspxq, a.fopty,\n",
    "\ta.gdwlq, a.ibq, a.invtq, a.intanq, a.ivaoq, a.lcoq, a.lctq, a.loq, a.ltq, a.mibq,\n",
    "\ta.niq, a.oancfy, a.oiadpq, a.oibdpq, a.piq, a.ppentq, a.ppegtq, a.prstkcy, a.prccq,\n",
    "\ta.pstkq, a.rdq, a.req, a.rectq, a.revtq, a.saleq, a.seqq, a.sstky, a.txdiq,\n",
    "\ta.txditcq, a.txpq, a.txtq, a.xaccq, a.xintq, a.xsgaq, a.xrdq, a.capxy\n",
    "    FROM comp_na_daily_all.fundq as a\n",
    "\tWHERE a.consol = 'C'\n",
    "\tAND a.popsrc = 'D'\n",
    "\tAND a.datafmt = 'STD'\n",
    "\tAND a.curcdq = 'USD'\n",
    "\tAND a.indfmt = 'INDL'\n",
    "    AND a.datadate BETWEEN '2005-01-01' AND '{current_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Read in Compustat Quarterly\n",
    "print(\"Read In Compustat Quarterly...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "compustat_quarterly = db.raw_sql(sql_compustat_quarterly)\n",
    "db.close()\n",
    "\n",
    "# Read in link table\n",
    "print(\"Read in link table...\")\n",
    "link_table = pd.read_parquet(get_parquet_dir(live) / 'data_link.parquet.brotli')\n",
    "link_table = link_table.drop(['cusip', 'conm'], axis=1)\n",
    "\n",
    "# Merge link table and Compustat Quarterly\n",
    "print(\"Merge link table and Compustat Quarterly...\")\n",
    "quarterly = compustat_quarterly.merge(link_table, on='gvkey', how='inner')\n",
    "\n",
    "# Keep only the most recent data for each fiscal quarter\n",
    "print(\"Keep only the most recent data for each fiscal quarter...\")\n",
    "quarterly = quarterly.sort_values(by=['gvkey', 'fyearq', 'fqtr', 'datadate'])\n",
    "quarterly = quarterly.groupby(['gvkey', 'fyearq', 'fqtr']).last().reset_index()\n",
    "\n",
    "# Convert to datetime\n",
    "print(\"Convert to datetime...\")\n",
    "quarterly['datadate'] = pd.to_datetime(quarterly['datadate'])\n",
    "quarterly['rdq'] = pd.to_datetime(quarterly['rdq'])\n",
    "\n",
    "# Shift data 3 months forward\n",
    "print(\"Shift data 3 months forward...\")\n",
    "quarterly['time_avail_m'] = (quarterly['datadate'] + pd.DateOffset(months=3)).dt.to_period('M')\n",
    "quarterly.loc[(~quarterly['rdq'].isnull()) & (quarterly['rdq'].dt.to_period('M') > quarterly['time_avail_m']), 'time_avail_m'] = quarterly['rdq'].dt.to_period('M')\n",
    "\n",
    "# Compute month difference\n",
    "print(\"Compute month difference...\")\n",
    "month_diff = (quarterly['rdq'] - quarterly['datadate']).dt.days // 30\n",
    "quarterly = quarterly.drop(quarterly[(month_diff > 6) & ~quarterly['rdq'].isnull()].index)\n",
    "quarterly = quarterly.sort_values(by=['gvkey', 'time_avail_m', 'datadate'])\n",
    "\n",
    "# Keep most recent data\n",
    "print(\"Keep most recent data...\")\n",
    "quarterly = quarterly.groupby(['gvkey', 'time_avail_m']).last().reset_index()\n",
    "\n",
    "# Create extra yearly columns\n",
    "print(\"Create extra yearly columns...\")\n",
    "for col in ['sstky', 'prstkcy', 'oancfy', 'fopty']:\n",
    "    grouped = quarterly.groupby(['gvkey', 'fyearq'])[col]\n",
    "    condition = quarterly['fqtr'] == 1\n",
    "    new_values = np.where(condition, quarterly[col], quarterly[col] - grouped.shift(1))\n",
    "    quarterly[col + 'q'] = new_values\n",
    "    \n",
    "# Convert index from quarterly to monthly\n",
    "print(\"Convert index from quarterly to monthly...\")\n",
    "quarterly = quarterly.loc[quarterly.index.repeat(3)]\n",
    "quarterly['tempTimeAvailM'] = quarterly['time_avail_m']\n",
    "quarterly = quarterly.sort_values(by=['gvkey', 'tempTimeAvailM'])\n",
    "quarterly['time_avail_m'] = quarterly.groupby(['gvkey', 'tempTimeAvailM']).cumcount() + quarterly['time_avail_m']\n",
    "\n",
    "# Sort values\n",
    "print(\"Sort values and keep most recent data...\")\n",
    "quarterly = quarterly.sort_values(by=['gvkey', 'time_avail_m', 'datadate'])\n",
    "# Keep most recent data\n",
    "quarterly = quarterly.groupby(['gvkey', 'time_avail_m']).last().reset_index()\n",
    "quarterly = quarterly.drop(columns=['tempTimeAvailM'])\n",
    "quarterly = quarterly.rename(columns={'datadate': 'datadateq', 'time_avail_m':'date'})\n",
    "\n",
    "# Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\n",
    "print(\"Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)...\")\n",
    "quarterly.date = quarterly.date.dt.to_timestamp(\"M\")\n",
    "quarterly = quarterly.set_index(['permno', 'date'])\n",
    "quarterly = quarterly.sort_index(level=['permno', 'date'])\n",
    "\n",
    "# Read in CRSP stock list\n",
    "if update_stock_list:\n",
    "    print(\"Read in CRSP stock list...\")\n",
    "    stock = read_stock(get_large_dir(live) / 'permno_crsp.csv')\n",
    "    quarterly = get_stocks_data(quarterly, stock)\n",
    "    print(\"Exporting stock list for live trading...\")\n",
    "    print(f'Number of stocks: {len(get_stock_idx(quarterly))}')\n",
    "    export_stock(quarterly, get_large_dir(live) / 'permno_compustat.csv')\n",
    "\n",
    "    # Export ticker list\n",
    "    print(\"Export ticker list...\")\n",
    "    ticker = link_table[link_table['permno'].isin(get_stock_idx(quarterly))]\n",
    "    ticker = ticker.set_index('ticker')\n",
    "    export_stock(ticker, get_large_dir(live) / 'ticker_compustat.csv')\n",
    "    \n",
    "# Convert data to numerical format (exclude columns that are not numerical format)\n",
    "print(\"Convert data to numerical format (exclude columns that are not numerical format)...\")\n",
    "numeric_cols = quarterly.select_dtypes(include=['number']).columns\n",
    "quarterly[numeric_cols] = quarterly[numeric_cols].astype(float)\n",
    "non_numeric_cols = quarterly.select_dtypes(exclude=['number']).columns\n",
    "quarterly_numeric = quarterly[numeric_cols]\n",
    "quarterly_numeric = quarterly_numeric.sort_index(level=['permno', 'date'])\n",
    "\n",
    "# Forward fill yearly data\n",
    "print(\"Forward fill yearly data...\")\n",
    "cols_to_fill = [col for col in quarterly_numeric.columns if col.endswith('y')]\n",
    "quarterly_numeric[cols_to_fill] = quarterly_numeric[cols_to_fill].ffill()\n",
    "\n",
    "# Export data\n",
    "print(\"Export data...\")\n",
    "quarterly_numeric.to_parquet(get_parquet_dir(live) / 'data_fund_raw_q.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3007e0-f5d8-4cdb-bf11-68e799b13f5a",
   "metadata": {},
   "source": [
    "# Compustat Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e5166f-b4e0-4275-9640-951156fe5452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read in Compustat Annual...\n",
      "Loading library list...\n",
      "Done\n",
      "Read in link table...\n",
      "Merge link table and Compustat Annual...\n",
      "Drop rows based on condition...\n",
      "Extract 6 digits from CUSIP...\n",
      "Replacing missing values...\n",
      "Shift data forward by 6 months...\n",
      "Convert index from annually to monthly...\n",
      "Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\n",
      "Set index and remove duplicate indices...\n",
      "Retrieve live trade stock list...\n",
      "Export data\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_compustat_annual = f\"\"\"\n",
    "    SELECT a.gvkey, a.datadate, a.conm, a.fyear, a.tic, a.cusip, a.naicsh, a.sich, \n",
    "    a.aco, a.act, a.ajex, a.am, a.ao, a.ap, a.at, a.capx, a.ceq, a.ceqt, a.che, a.cogs,\n",
    "    a.csho, a.cshrc, a.dcpstk, a.dcvt, a.dlc, a.dlcch, a.dltis, a.dltr,\n",
    "    a.dltt, a.dm, a.dp, a.drc, a.drlt, a.dv,a.dvc,a.dvp,a.dvpa,a.dvpd,\n",
    "    a.dvpsx_c, a.dvt, a.ebit, a.ebitda, a.emp, a.epspi, a.epspx, a.fatb, a.fatl,\n",
    "    a.ffo, a.fincf, a.fopt, a.gdwl, a.gdwlia, a.gdwlip, a.gwo, a.ib, a.ibcom,\n",
    "    a.intan, a.invt, a.ivao, a.ivncf, a.ivst, a.lco, a.lct, a.lo ,a.lt, a.mib,\n",
    "    a.msa, a.ni, a.nopi, a.oancf, a.ob, a.oiadp, a.oibdp, a.pi, a.ppenb, a.ppegt,\n",
    "    a.ppenls, a.ppent, a.prcc_c, a.prcc_f, a.prstkc, a.prstkcc, a.pstk, a.pstkl, a.pstkrv,\n",
    "    a.re, a.rect, a.recta, a.revt, a.sale, a.scstkc, a.seq, a.spi, a.sstk,\n",
    "    a.tstkp, a.txdb, a.txdi, a.txditc, a.txfo, a.txfed, a.txp, a.txt,\n",
    "    a.wcap, a.wcapch, a.xacc, a.xad, a.xint, a.xrd, a.xpp, a.xsga\n",
    "    FROM comp_na_daily_all.funda as a\n",
    "    WHERE a.consol = 'C'\n",
    "    AND a.popsrc = 'D'\n",
    "    AND a.datafmt = 'STD'\n",
    "    AND a.curcd = 'USD'\n",
    "    AND a.indfmt = 'INDL'\n",
    "    AND a.datadate BETWEEN '2005-01-01' AND '{current_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Read in Compustat Annual\n",
    "print(\"Read in Compustat Annual...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "compustat_annual = db.raw_sql(sql_compustat_annual)\n",
    "db.close()\n",
    "\n",
    "# Read in link table\n",
    "print(\"Read in link table...\")\n",
    "link_table = pd.read_parquet(get_parquet_dir(live) / 'data_link.parquet.brotli')\n",
    "link_table = link_table.drop(['cusip', 'conm'], axis=1)\n",
    "\n",
    "# Merge link table and Compustat Annual\n",
    "print(\"Merge link table and Compustat Annual...\")\n",
    "annual = compustat_annual.merge(link_table, on='gvkey', how='inner')\n",
    "\n",
    "# Drop rows based on condition\n",
    "print(\"Drop rows based on condition...\")\n",
    "annual = annual.dropna(subset=['at', 'prcc_c', 'ni'])\n",
    "\n",
    "# Extract 6 digits from CUSIP\n",
    "print(\"Extract 6 digits from CUSIP...\")\n",
    "annual['cnum'] = annual['cusip'].str[:6]\n",
    "\n",
    "# Replacing missing values\n",
    "print(\"Replacing missing values...\")\n",
    "annual['dr'] = annual.apply(lambda row: row['drc'] + row['drlt'] if pd.notna(row['drc']) and pd.notna(row['drlt']) else (row['drc'] if pd.notna(row['drc']) else (row['drlt'] if pd.notna(row['drlt']) else None)), axis=1)\n",
    "annual.loc[(annual['dcpstk'] > annual['pstk']) & pd.notna(annual['dcpstk']) & pd.notna(annual['pstk']) & pd.isna(annual['dcvt']), 'dc'] = annual['dcpstk'] - annual['pstk']\n",
    "annual.loc[pd.isna(annual['pstk']) & pd.notna(annual['dcpstk']) & pd.isna(annual['dcvt']), 'dc'] = annual['dcpstk']\n",
    "annual.loc[pd.isna(annual['dc']), 'dc'] = annual['dcvt']\n",
    "annual['xint0'] = annual['xint'].fillna(0)\n",
    "annual['xsga0'] = annual['xsga'].fillna(0)\n",
    "annual['xad0'] = annual.apply(lambda row: 0 if row['xad'] < 0 else row['xad'], axis=1)\n",
    "vars_list = ['nopi', 'dvt', 'ob', 'dm', 'dc', 'aco', 'ap', 'intan', 'ao', 'lco', 'lo', 'rect', 'invt', 'drc', 'spi', 'gdwl', 'che', 'dp', 'act', 'lct', 'tstkp', 'dvpa', 'scstkc', 'sstk', 'mib', 'ivao', 'prstkc', 'prstkcc', 'txditc', 'ivst']\n",
    "for var in vars_list:\n",
    "    annual[var].fillna(0, inplace=True)\n",
    "\n",
    "# Shift data forward by 6 months\n",
    "print(\"Shift data forward by 6 months...\")\n",
    "annual['date'] = pd.to_datetime(annual['datadate']).dt.to_period('M') + 6\n",
    "\n",
    "# Convert index from annually to monthly\n",
    "print(\"Convert index from annually to monthly...\")\n",
    "annual = annual.reindex(annual.index.repeat(12))\n",
    "annual['tempTime'] = annual.groupby(['gvkey', 'date']).cumcount()\n",
    "annual['date'] += annual['tempTime']\n",
    "annual = annual.drop(columns=['tempTime'])\n",
    "\n",
    "# Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\n",
    "print(\"Convert from YY-MM to YY-MM-DD (2012-01 to 2012-01-31)\")\n",
    "annual.date = annual.date.dt.to_timestamp(\"M\")\n",
    "annual = annual.drop('datadate', axis=1)\n",
    "\n",
    "# Set index and remove duplicate indices\n",
    "print(\"Set index and remove duplicate indices...\")\n",
    "annual = annual.set_index(['permno', 'date'])\n",
    "annual = annual.sort_index(level=['permno', 'date'])\n",
    "annual = annual[~annual.index.duplicated(keep='first')]\n",
    "\n",
    "# Retrieve live trade stock list\n",
    "print(\"Retrieve live trade stock list...\")\n",
    "stock = read_stock(get_large_dir(live) / 'permno_compustat.csv')\n",
    "annual = get_stocks_data(annual, stock)\n",
    "\n",
    "# Export data\n",
    "print(\"Export data\")\n",
    "annual.to_parquet(get_parquet_dir(live) / 'data_fund_raw_a.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d896b9e-ba61-4a58-a5d2-2c67e4d66315",
   "metadata": {},
   "source": [
    "# Live Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1033131-39eb-4c70-a353-d28da239f6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read in live market data...\n",
      "[*********************100%%**********************]  856 of 856 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "111 Failed downloads:\n",
      "['FBC', 'CMMCY', 'ZSANQ', 'WINMQ', 'FDC', 'BASXQ', 'CXO', 'ZEN', 'IVANF', 'LM', 'LN', 'SDLPQ', 'CELG', 'SC', 'SCON', 'WHCI', 'QTNTQ', 'AVP', 'TSS', 'NRTLQ', 'BFB', 'FTSI', 'PIRRQ', 'CLR', 'Y', 'BPY', 'KL', 'STOR', 'CPPRQ', 'CDK', 'VAR', 'SQBGQ', 'PSXP', 'CTXS', 'WPSL', 'BRKB', 'FRANQ', 'TIF', 'COUP', 'CERN', 'TWTR', 'NBL', 'XEC', 'ATH', 'TTPH', 'RTN', 'AIBYY', 'RRD', 'XLNX', 'WPGGQ', 'APC', 'GG', 'MDRIQ', 'NLSN', 'NIHD', 'WLL', 'DRE', 'IOGPQ', 'IAA', 'PBCT', 'CHNG', 'BPL', 'AVLR', 'JENGQ', 'KSU', 'ALXN', 'ZAYO', 'AUY', 'QTWWQ', 'STI', 'PRAH']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "['DPS', 'LEHMQ', 'FDO', 'WWAV', 'THQIQ', 'SCMR', 'LLTC', 'GNVC', 'ELN', 'HCBK', 'HSP', 'CAM', 'TWC', 'CFN', 'XTO', 'STJ', 'GENZ', 'LVLT', 'ARG', 'THMRQ', 'KMP', 'RAI', 'WYE', 'SPLS', 'SWY', 'LNKD', 'BRCM', 'TLM', 'EPB', 'APOL', 'BCR', 'SIAL', 'SNDK', 'LO', 'AGU', 'MJN', 'FMD', 'FSL', 'EDS']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2005-01-01 -> 2023-10-20)')\n",
      "['OCNF']: Exception(\"%ticker%: Period 'max' is invalid, must be one of ['1d', '5d']\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "ticker_list = read_stock(get_large_dir(live) / 'ticker_compustat.csv')\n",
    "\n",
    "# Read in live market data\n",
    "print(\"Read in live market data...\")\n",
    "price = yf.download(ticker_list, start='2005-01-01', end=current_date)\n",
    "price = price.stack().swaplevel().sort_index()\n",
    "price.index.names = ['ticker', 'date']\n",
    "price = price.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7517c6a-6050-4315-a872-e06a1df2fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in link table...\n",
      "Merge link table and Live Market Price...\n",
      "Remove duplicate indices (there should be none)...\n",
      "Exporting Price...\n",
      "Export Date...\n",
      "Exporting Tickers...\n",
      "Exporting permno list for live trading...\n",
      "Number of stocks: 745\n",
      "Exporting ticker list for live trading...\n",
      "Number of stocks: 745\n"
     ]
    }
   ],
   "source": [
    "# Read in link table\n",
    "print(\"Read in link table...\")\n",
    "link_table = pd.read_parquet(get_parquet_dir(live) / 'data_link.parquet.brotli')\n",
    "\n",
    "# Merge link table and Live Market Price\n",
    "print(\"Merge link table and Live Market Price...\")\n",
    "price = price.reset_index()\n",
    "price = price.merge(link_table, on='ticker', how='inner')\n",
    "price = price.reset_index().set_index(['permno', 'date'])\n",
    "price = price.sort_index(level=['permno', 'date'])\n",
    "\n",
    "# Remove duplicate indices (there should be none)\n",
    "print(\"Remove duplicate indices (there should be none)...\")\n",
    "price = price[~price.index.duplicated(keep='first')]\n",
    "\n",
    "# Export ohclv\n",
    "print('Exporting Price...')\n",
    "ohclv = price[['Open', 'High', 'Close', 'Low', 'Volume']]\n",
    "ohclv.to_parquet(get_parquet_dir(live) / 'data_price.parquet.brotli', compression='brotli')\n",
    "\n",
    "# Export date\n",
    "print('Export Date...')\n",
    "date = price.drop(columns=price.columns)\n",
    "date.to_parquet(get_parquet_dir(live) / 'data_date.parquet.brotli', compression='brotli')\n",
    "\n",
    "# Export ticker\n",
    "print('Exporting Tickers...')\n",
    "ticker = price[['ticker']]\n",
    "ticker.to_parquet(get_parquet_dir(live) / 'data_ticker.parquet.brotli', compression='brotli')\n",
    "\n",
    "print(\"Exporting permno list for live trading...\")\n",
    "print(f'Number of stocks: {len(get_stock_idx(ohclv))}')\n",
    "export_stock(ohclv, get_large_dir(live) / 'permno_live.csv')\n",
    "\n",
    "print(\"Exporting ticker list for live trading...\")\n",
    "ticker = ticker.reset_index()\n",
    "ticker = ticker.set_index('ticker')\n",
    "print(f'Number of stocks: {len(get_stock_idx(ticker))}')\n",
    "export_stock(ticker, get_large_dir(live) / 'ticker_live.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929c515-c008-4284-9aff-0c0b437737b2",
   "metadata": {},
   "source": [
    "# Compustat Pension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c07c93b2-8cf3-4b47-bf1a-43c58867dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read in Pension Annual...\n",
      "Loading library list...\n",
      "Done\n",
      "Drop duplicate indices...\n",
      "Convert to datetime and set index...\n",
      "Shift everything 1 year forward...\n",
      "Export data...\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_compustat_pension = f\"\"\"\n",
    "    SELECT a.gvkey, a.datadate, a.paddml, a.pbnaa, a.pbnvv, a.pbpro, \n",
    "\t       a.pbpru, a.pcupsu, a.pplao, a.pplau\n",
    "    FROM comp_na_daily_all.aco_pnfnda as a\n",
    "\tWHERE a.consol = 'C'\n",
    "\tAND a.popsrc = 'D'\n",
    "\tAND a.datafmt = 'STD'\n",
    "\tAND a.indfmt = 'INDL'\n",
    "    AND a.datadate BETWEEN '2005-01-01' AND '{current_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Read in Pension Annual\n",
    "print(\"Read in Pension Annual...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "pension = db.raw_sql(sql_compustat_pension)\n",
    "db.close()\n",
    "\n",
    "# Drop duplicate indices\n",
    "print(\"Drop duplicate indices...\")\n",
    "pension = pension.sort_values(by=['gvkey', 'datadate'])\n",
    "pension = pension.groupby(['gvkey', 'datadate']).last().reset_index()\n",
    "\n",
    "# Convert to datetime and set index\n",
    "print(\"Convert to datetime and set index...\")\n",
    "pension['datadate'] = pd.to_datetime(pension['datadate'])\n",
    "pension = pension.rename(columns = {'datadate': 'date', 'tic': 'ticker'})\n",
    "pension = pension.set_index('date')\n",
    "\n",
    "# Shift everything 1 year forward\n",
    "print(\"Shift everything 1 year forward...\")\n",
    "for col in pension.columns:\n",
    "    if col != 'gvkey' or col != 'indfmt' or col != 'datafmt' or col != 'consol' or col != 'popsrc' or col != 'ticker':\n",
    "        pension[col] = pension.groupby('gvkey')[col].shift(1)\n",
    "\n",
    "# Export data\n",
    "print(\"Export data...\")\n",
    "pension.to_parquet(get_parquet_dir(live) / 'data_pension.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf873f6-83fa-46ef-b82c-2a461e2085be",
   "metadata": {},
   "source": [
    "# Compustat Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f928ed1-8e35-466c-a8d6-f559b21197bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Read in Compustat Industry...\n",
      "Loading library list...\n",
      "Done\n",
      "Read in CRSP Industry...\n",
      "Loading library list...\n",
      "Done\n",
      "Read in link table...\n",
      "Merge link table and Compustat Annual...\n",
      "Rename columns...\n",
      "Remove duplicate permno...\n",
      "Assign Fama industries based off given ranges\n",
      "Iterate through each key...\n",
      "------------------------------------------------------------\n",
      "agric\n",
      "------------------------------------------------------------\n",
      "food\n",
      "------------------------------------------------------------\n",
      "soda\n",
      "------------------------------------------------------------\n",
      "beer\n",
      "------------------------------------------------------------\n",
      "smoke\n",
      "------------------------------------------------------------\n",
      "toys\n",
      "------------------------------------------------------------\n",
      "fun\n",
      "------------------------------------------------------------\n",
      "books\n",
      "------------------------------------------------------------\n",
      "hshld\n",
      "------------------------------------------------------------\n",
      "clths\n",
      "------------------------------------------------------------\n",
      "hlth\n",
      "------------------------------------------------------------\n",
      "medeq\n",
      "------------------------------------------------------------\n",
      "drugs\n",
      "------------------------------------------------------------\n",
      "chems\n",
      "------------------------------------------------------------\n",
      "rubbr\n",
      "------------------------------------------------------------\n",
      "txtls\n",
      "------------------------------------------------------------\n",
      "bldmt\n",
      "------------------------------------------------------------\n",
      "cnstr\n",
      "------------------------------------------------------------\n",
      "steel\n",
      "------------------------------------------------------------\n",
      "fabpr\n",
      "------------------------------------------------------------\n",
      "mach\n",
      "------------------------------------------------------------\n",
      "elceq\n",
      "------------------------------------------------------------\n",
      "autos\n",
      "------------------------------------------------------------\n",
      "aero\n",
      "------------------------------------------------------------\n",
      "ships\n",
      "------------------------------------------------------------\n",
      "guns\n",
      "------------------------------------------------------------\n",
      "gold\n",
      "------------------------------------------------------------\n",
      "mines\n",
      "------------------------------------------------------------\n",
      "coal\n",
      "------------------------------------------------------------\n",
      "oil\n",
      "------------------------------------------------------------\n",
      "util\n",
      "------------------------------------------------------------\n",
      "telcm\n",
      "------------------------------------------------------------\n",
      "persv\n",
      "------------------------------------------------------------\n",
      "bussv\n",
      "------------------------------------------------------------\n",
      "hardw\n",
      "------------------------------------------------------------\n",
      "softw\n",
      "------------------------------------------------------------\n",
      "chips\n",
      "------------------------------------------------------------\n",
      "labeq\n",
      "------------------------------------------------------------\n",
      "paper\n",
      "------------------------------------------------------------\n",
      "boxes\n",
      "------------------------------------------------------------\n",
      "trans\n",
      "------------------------------------------------------------\n",
      "whlsl\n",
      "------------------------------------------------------------\n",
      "rtail\n",
      "------------------------------------------------------------\n",
      "meals\n",
      "------------------------------------------------------------\n",
      "banks\n",
      "------------------------------------------------------------\n",
      "insur\n",
      "------------------------------------------------------------\n",
      "rlest\n",
      "------------------------------------------------------------\n",
      "fin\n",
      "------------------------------------------------------------\n",
      "other\n",
      "Assign industry based off Compustat. If Compustat is NAN, then use CRSP...\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 60)\n",
    "sql_compustat_industry = f\"\"\"\n",
    "    SELECT a.gvkey, a.gind, a.gsubind, a.sic\n",
    "    FROM comp_na_daily_all.names as a\n",
    "\"\"\"\n",
    "\n",
    "sql_crsp_industry = f\"\"\"\n",
    "    SELECT a.permno, a.siccd\n",
    "    FROM crsp_a_stock.dsenames as a\n",
    "\"\"\"\n",
    "\n",
    "# Read in Compustat Industry\n",
    "print(\"Read in Compustat Industry...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "industry_compustat = db.raw_sql(sql_compustat_industry)\n",
    "industry_compustat = industry_compustat.rename(columns={'sic': 'sic_comp'})\n",
    "industry_compustat['sic_comp'] = industry_compustat['sic_comp'].astype(int)\n",
    "db.close()\n",
    "\n",
    "# Read in CRSP Industry\n",
    "print(\"Read in CRSP Industry...\")\n",
    "db = wrds.Connection(wrds_username='jofan23')\n",
    "industry_crsp = db.raw_sql(sql_crsp_industry)\n",
    "industry_crsp = industry_crsp.rename(columns={'siccd': 'sic_crsp'})\n",
    "industry_crsp['sic_crsp'] = industry_crsp['sic_crsp'].astype(int)\n",
    "db.close()\n",
    "\n",
    "# Read in link table\n",
    "print(\"Read in link table...\")\n",
    "link_table = pd.read_parquet(get_parquet_dir(live) / 'data_link.parquet.brotli')\n",
    "link_table = link_table.drop(['conm', 'sic'], axis=1)\n",
    "\n",
    "# Merge link table and Compustat Annual\n",
    "print(\"Merge link table and Compustat Annual...\")\n",
    "industry = pd.merge(industry_compustat, link_table, on='gvkey', how='inner')\n",
    "industry = industry.merge(industry_crsp, on='permno', how='inner')\n",
    "\n",
    "# Rename Columns\n",
    "print('Rename columns...')\n",
    "industry.columns = industry.columns.str.lower()\n",
    "industry = industry.rename(columns={'gsubind':'Subindustry', 'gind':'Industry'})\n",
    "\n",
    "# Remove duplicate permno\n",
    "print('Remove duplicate permno...')\n",
    "industry = industry.drop_duplicates(subset='permno')\n",
    "industry = industry[['permno', 'Industry', 'Subindustry', 'sic_crsp', 'sic_comp']]\n",
    "\n",
    "# Assign Fama industries based off given ranges\n",
    "print(\"Assign Fama industries based off given ranges...\")\n",
    "def assign_ind(df, column_name, sic_ranges, label):\n",
    "    # Sic from CRSP and Compustat\n",
    "    df['sic_temp_crsp'] = df['sic_crsp']\n",
    "    df['sic_temp_comp'] = df['sic_comp']\n",
    "\n",
    "    # Iterate through each range and assign industry\n",
    "    for r in sic_ranges:\n",
    "        if isinstance(r, tuple):\n",
    "            df.loc[(df['sic_temp_crsp'] >= r[0]) & (df['sic_temp_crsp'] <= r[1]), f'{column_name}_crsp'] = label\n",
    "            df.loc[(df['sic_temp_comp'] >= r[0]) & (df['sic_temp_comp'] <= r[1]), f'{column_name}_comp'] = label\n",
    "        else:\n",
    "            df.loc[df['sic_temp_crsp'] == r, f'{column_name}_crsp'] = label\n",
    "            df.loc[df['sic_temp_comp'] == r, f'{column_name}_comp'] = label\n",
    "    \n",
    "    df = df.drop(columns=['sic_temp_crsp', 'sic_temp_comp'])\n",
    "    return df\n",
    "    \n",
    "# FF49 Industry ranges\n",
    "fama_ind = {\n",
    "'agric': [(100, 199), (200, 299), (700, 799), (910, 919), 2048],\n",
    "'food': [(2000, 2009), (2010, 2019), (2020, 2029), (2030, 2039), (2040, 2046), (2050, 2059), (2060, 2063), (2070, 2079), (2090, 2092), 2095, (2098, 2099)],\n",
    "'soda': [(2064, 2068), 2086, 2087, 2096, 2097],\n",
    "'beer': [2080, 2082, 2083, 2084, 2085],\n",
    "'smoke': [(2100, 2199)],\n",
    "'toys': [(920, 999), (3650, 3651), 3652, 3732, (3930, 3931), (3940, 3949)],\n",
    "'fun': [(7800, 7829), (7830, 7833), (7840, 7841), 7900, (7910, 7911), (7920, 7929), (7930, 7933), (7940, 7949), 7980, (7990, 7999)],\n",
    "'books': [(2700, 2709), (2710, 2719), (2720, 2729), (2730, 2739), (2740, 2749), (2770, 2771), (2780, 2789), (2790, 2799)],\n",
    "'hshld': [2047, (2391, 2392), (2510, 2519), (2590, 2599), (2840, 2843), 2844, (3160, 3161), (3170, 3171), 3172, (3190, 3199), 3229, 3260, (3262, 3263), 3269, (3230, 3231), (3630, 3639), (3750, 3751), 3800, (3860, 3861), (3870, 3873), (3910, 3911), 3914, 3915, (3960, 3962), 3991, 3995],\n",
    "'clths': [(2300, 2390), (3020, 3021), (3100, 3111), (3130, 3131), (3140, 3149), (3150, 3151), (3963, 3965)],\n",
    "'hlth': [(8000, 8099)],\n",
    "'medeq': [3693, (3840, 3849), (3850, 3851)],\n",
    "'drugs': [2830, 2831, 2833, 2834, 2835, 2836],\n",
    "'chems': [(2800, 2809), (2810, 2819), (2820, 2829), (2850, 2859), (2860, 2869), (2870, 2879), (2890, 2899)],\n",
    "'rubbr': [3031, 3041, (3050, 3053), (3060, 3069), (3070, 3079), (3080, 3089), (3090, 3099)],\n",
    "'txtls': [(2200, 2269), (2270, 2279), (2280, 2284), (2290, 2295), 2297, 2298, 2299, (2393, 2395), (2397, 2399)],\n",
    "'bldmt': [(800, 899), (2400, 2439), (2450, 2459), (2490, 2499), (2660, 2661), (2950, 2952), 3200, (3210, 3211), (3240, 3241), (3250, 3259), 3261, 3264, (3270, 3275), (3280, 3281), (3290, 3293), (3295, 3299), (3420, 3429), (3430, 3433), (3440, 3441), 3442, 3446, 3448, 3449, (3450, 3451), 3452, (3490, 3499), 3996],\n",
    "'cnstr': [(1500, 1511), (1520, 1529), (1530, 1539), (1540, 1549), (1600, 1699), (1700, 1799)],\n",
    "'steel': [3300, (3310, 3317), (3320, 3325), (3330, 3339), (3340, 3341), (3350, 3357), (3360, 3369), (3370, 3379), (3390, 3399)],\n",
    "'fabpr': [3400, 3443, 3444, (3460, 3469), (3470, 3479)],\n",
    "'mach': [(3510, 3519), (3520, 3529), 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3538, (3540, 3549), (3550, 3559), (3560, 3569), 3580, 3581, 3582, 3585, 3586, 3589, (3590, 3599)],\n",
    "'elceq': [3600, (3610, 3613), (3620, 3621), (3623, 3629), (3640, 3644), 3645, 3646, (3648, 3649), 3660, 3690, (3691, 3692), 3699],\n",
    "'autos': [2296, 2396, (3010, 3011), 3537, 3647, 3694, 3700, 3710, 3711, 3713, 3714, 3715, 3716, 3792, (3790, 3791), 3799],\n",
    "'aero': [3720, 3721, (3723, 3724), 3725, (3728, 3729)],\n",
    "'ships': [(3730, 3731), (3740, 3743)],\n",
    "'guns': [(3760, 3769), 3795, (3480, 3489)],\n",
    "'gold': [(1040, 1049)],\n",
    "'mines': [(1000, 1009), (1010, 1019), (1020, 1029), (1030, 1039), (1050, 1059), (1060, 1069), (1070, 1079), (1080, 1089), (1090, 1099), (1100, 1119), (1400, 1499)],\n",
    "'coal': [(1200, 1299)],\n",
    "'oil': [1300, (1310, 1319), (1320, 1329), (1330, 1339), (1370, 1379), 1380, 1381, 1382, 1389, (2900, 2912), (2990, 2999)],\n",
    "'util': [4900, (4910, 4911), (4920, 4922), 4923, (4924, 4925), (4930, 4931), 4932, 4939, (4940, 4942)],\n",
    "'telcm': [4800, (4810, 4813), (4820, 4822), (4830, 4839), (4840, 4841), 4880, 4890, 4891, 4892, 4899],\n",
    "'persv': [(7020, 7021), (7030, 7033), 7200, (7210, 7212), 7214, (7215, 7216), 7217, 7219, (7220, 7221), (7230, 7231), (7240, 7241), (7250, 7251), (7260, 7269), (7270, 7290), 7291, (7292, 7299), 7395, 7500, (7520, 7529), (7530, 7539), (7540, 7549), 7600, 7620, 7622, 7623, 7629, 7630, 7640, (7690, 7699), (8100, 8199), (8200, 8299), (8300, 8399), (8400, 8499), (8600, 8699), (8800, 8899), (7510, 7515)],\n",
    "'bussv': [(2750, 2759), 3993, 7218, 7300, (7310, 7319), (7320, 7329), (7330, 7339), (7340, 7342), 7349, (7350, 7351), 7352, 7353, 7359, (7360, 7369), 7374, 7376, 7377, 7378, 7379, 7380, (7381, 7382), 7383, 7384, 7385, 7389, 7390, 7391, (7392, 7392), 7393, 7394, 7396, 7397, 7399, (7519, 7519), 8700, (8710, 8713), (8720, 8721), (8730, 8734), (8740, 8748), (8900, 8910), 8911, (8920, 8999), (4220, 4229)],\n",
    "'hardw': [(3570, 3579), 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3695],\n",
    "'softw': [(7370, 7372), 7375, 7373],\n",
    "'chips': [3622, 3661, (3662, 3662), 3663, 3664, 3665, 3666, 3669, (3670, 3679), (3810, 3810), (3812, 3812)],\n",
    "'labeq': [3811, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3829, (3830, 3839)],\n",
    "'paper': [(2520, 2549), (2600, 2639), (2670, 2699), (2760, 2761), (3950, 3955)],\n",
    "'boxes': [(2440, 2449), (2640, 2659), (3220, 3221), (3410, 3412)],\n",
    "'trans': [(4000, 4013), (4040, 4049), 4100, (4110, 4119), (4120, 4121), (4130, 4131), (4140, 4142), (4150, 4151), (4170, 4173), (4190, 4199), 4200, (4210, 4219), (4230, 4231), (4240, 4249), (4400, 4499), (4500, 4599), (4600, 4699), 4700, (4710, 4712), (4720, 4729), (4730, 4739), (4740, 4749), 4780, 4782, 4783, 4784, 4785, 4789],\n",
    "'whlsl': [5000, (5010, 5015), (5020, 5023), (5030, 5039), (5040, 5042), 5043, 5044, 5045, 5046, 5047, 5048, 5049, (5050, 5059), 5060, 5063, 5064, 5065, (5070, 5078), 5080, 5081, 5082, 5083, 5084, 5085, (5086, 5087), 5088, 5090, (5091, 5092), 5093, 5094, 5099, 5100, (5110, 5113), (5120, 5122), (5130, 5139), (5140, 5149), (5150, 5159), (5160, 5169), (5170, 5172), (5180, 5182), (5190, 5199)],\n",
    "'rtail': [5200, (5210, 5219), (5220, 5229), (5230, 5231), (5250, 5251), (5260, 5261), (5270, 5271), 5300, 5310, 5320, (5330, 5331), 5334, (5340, 5349), (5390, 5399), 5400, (5410, 5411), 5412, (5420, 5429), (5430, 5439), (5440, 5449), (5450, 5459), (5460, 5469), (5490, 5499), 5500, (5510, 5529), (5530, 5539), (5540, 5549), (5550, 5559), (5560, 5569), (5570, 5579), (5590, 5599), (5600, 5699), 5700, (5710, 5719), (5720, 5722), (5730, 5733), 5734, 5735, 5736, (5750, 5799), 5900, (5910, 5912), (5920, 5929), (5930, 5932), 5940, 5941, 5942, 5943, 5944, 5945, 5946, 5947, 5948, 5949, (5950, 5959), (5960, 5969), (5970, 5979), (5980, 5989), 5990, 5992, 5993, 5994, 5995, 5999],\n",
    "'meals': [(5800, 5819), (5820, 5829), (5890, 5899), 7000, (7010, 7019), (7040, 7049), 7213],\n",
    "'banks': [6000, (6010, 6019), 6020, 6021, 6022, 6023, 6025, 6026, 6027, (6028, 6029), (6030, 6036), (6040, 6059), (6060, 6062), (6080, 6082), (6090, 6099), 6100, (6110, 6111), (6112, 6113), (6120, 6129), (6130, 6139), (6140, 6149), (6150, 6159), (6160, 6169), (6170, 6179), (6190, 6199)],\n",
    "'insur': [6300, (6310, 6319), (6320, 6329), (6330, 6331), (6350, 6351), (6360, 6361), (6370, 6379), (6390, 6399), (6400, 6411)],\n",
    "'rlest': [6500, 6510, 6512, 6513, 6514, 6515, (6517, 6519), (6520, 6529), (6530, 6531), 6532, (6540, 6541), (6550, 6553), (6590, 6599), (6610, 6611)],\n",
    "'fin': [(6200, 6299), 6700, (6710, 6719), (6720, 6722), 6723, 6724, 6725, 6726, (6730, 6733), (6740, 6779), 6790, 6791, 6792, 6793, 6794, 6795, 6798, 6799],\n",
    "'other': [(4950, 4959), (4960, 4961), (4970, 4971), (4990, 4991)]\n",
    "}\n",
    "\n",
    "# Iterate through each key\n",
    "print(\"Iterate through each key...\")\n",
    "for name, ranges in fama_ind.items():\n",
    "    print('-'*60)\n",
    "    print(name)\n",
    "    combined = assign_ind(industry, 'IndustryFama', ranges, name)\n",
    "\n",
    "# Assign industry based off Compustat. If Compustat is NAN, then use CRSP\n",
    "print(\"Assign industry based off Compustat. If Compustat is NAN, then use CRSP...\")\n",
    "industry['IndustryFama'] = industry['IndustryFama_comp'].combine_first(industry['IndustryFama_crsp'])\n",
    "industry['IndustryFama'], category_mapping = industry['IndustryFama'].factorize()\n",
    "\n",
    "# Fill NAN values for industries with -1\n",
    "print(\"Fill industries with -1...\")\n",
    "cols_to_fill = ['Industry', 'Subindustry', 'IndustryFama']\n",
    "industry = industry[cols_to_fill].fillna(-1)\n",
    "\n",
    "# Retrieve live trade stock list\n",
    "print(\"Retrieve live trade stock list...\")\n",
    "stock = read_stock(get_large_dir(live) / 'permno_live.csv')\n",
    "industry = industry[industry['permno'].isin(stock)]\n",
    "\n",
    "# Merge ind data with price dataset\n",
    "print(\"Merge ind data with price dataset...\")\n",
    "date = pd.read_parquet(get_parquet_dir(live) / 'data_date.parquet.brotli')\n",
    "date = date.reset_index(level='permno')\n",
    "industry = pd.merge(date, industry, on=['permno'], how='inner')\n",
    "industry = industry.reset_index().set_index(['permno', 'date']).sort_index(level=['permno', 'date'])\n",
    "industry = industry.groupby('permno').ffill()\n",
    "industry = industry[~industry.index.duplicated(keep='first')]\n",
    "industry = industry.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Export industry\n",
    "print(\"Exporting Industries...\")\n",
    "industry[['Industry']].to_parquet(get_parquet_dir(live) / 'data_ind.parquet.brotli', compression='brotli')\n",
    "industry[['Subindustry']].to_parquet(get_parquet_dir(live) / 'data_ind_sub.parquet.brotli', compression='brotli')\n",
    "industry[['IndustryFama']].to_parquet(get_parquet_dir(live) / 'data_ind_fama.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5eb7e4-a44e-4efe-9cab-a14a0029a7cb",
   "metadata": {},
   "source": [
    "# Fama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "009a4ecd-47ba-4f18-adea-222561088e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Fama data from web\n",
    "fama_data = (web.DataReader('F-F_Research_Data_5_Factors_2x3_daily', 'famafrench', start=2005)[0].rename(columns={'Mkt-RF': 'MARKET'}))\n",
    "fama_data.index.names = ['date']\n",
    "fama_data = fama_data.astype(float)\n",
    "fama_data.to_parquet(get_parquet_dir(live) / 'data_fama.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e8b0e-2ad2-4f85-833d-a81b87c5041a",
   "metadata": {},
   "source": [
    "# Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79929cf5-700b-43ef-9119-5e310dd2c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in Median CPI...\n"
     ]
    }
   ],
   "source": [
    "# API key\n",
    "fred = Fred(api_key='00e07a5c98e913ea393c3b1f089e21d1')\n",
    "\n",
    "# Read in Median CPI\n",
    "print(\"Read in Median CPI...\")\n",
    "medianCPI = fred.get_series(\"MEDCPIM158SFRBCLE\").to_frame()\n",
    "medianCPI = medianCPI.reset_index()\n",
    "medianCPI.columns = ['date', 'medCPI']\n",
    "\n",
    "# Export data\n",
    "print(\"Export data...\")\n",
    "medianCPI.to_csv(get_large_dir(True) / 'macro' / 'medianCPI.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algofacto",
   "language": "python",
   "name": "algofacto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
